{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_len  sepal_wid  petal_len  petal_wid        class\n",
       "0        5.1        3.5        1.4        0.2  Iris-setosa\n",
       "1        4.9        3.0        1.4        0.2  Iris-setosa\n",
       "2        4.7        3.2        1.3        0.2  Iris-setosa\n",
       "3        4.6        3.1        1.5        0.2  Iris-setosa\n",
       "4        5.0        3.6        1.4        0.2  Iris-setosa"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "data = pd.read_csv(\n",
    "    filepath_or_buffer='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "    header=None,\n",
    "    sep=',')\n",
    "\n",
    "data.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n",
    "data.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix \n",
      "[[ 1.00671141 -0.11010327  0.87760486  0.82344326]\n",
      " [-0.11010327  1.00671141 -0.42333835 -0.358937  ]\n",
      " [ 0.87760486 -0.42333835  1.00671141  0.96921855]\n",
      " [ 0.82344326 -0.358937    0.96921855  1.00671141]]\n",
      "Eigen vectors \n",
      "[[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
      " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n",
      "Eigen values \n",
      "[2.93035378 0.92740362 0.14834223 0.02074601]\n",
      "\n",
      "Eigen vectors obtained after decomposition of the standardized data \n",
      "[[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
      " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n",
      "Eigen values are: \n",
      "[2.91081808 0.92122093 0.14735328 0.02060771]\n",
      "\n",
      " Eigen vectors obtained after decomposition of the raw data \n",
      "[[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
      " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n",
      "Eigen values are:\n",
      "[2.91081808 0.92122093 0.14735328 0.02060771]\n",
      "\n",
      "\n",
      "Eigen values in descending order:\t\n",
      "2.910818083752051\n",
      "0.9212209307072246\n",
      "0.14735327830509562\n",
      "0.02060770723562511\n",
      "\n",
      " Original matrix is:\n",
      " [[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
      " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n",
      "\n",
      "Matrix W after deleting last row:\n",
      " [[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
      " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
      " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]]\n",
      "\n",
      "Transposed Matrix:\n",
      "[[ 0.52237162 -0.26335492  0.58125401]\n",
      " [-0.37231836 -0.92555649 -0.02109478]\n",
      " [-0.72101681  0.24203288  0.14089226]\n",
      " [ 0.26199559 -0.12413481 -0.80115427]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USERRR\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "C:\\Users\\USERRR\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Split data into X data & y classes\n",
    "X = data.ix[:,0:4].values\n",
    "y = data.ix[:,4].values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "import numpy as np\n",
    "mean_vec = np.mean(X_std, axis=0)\n",
    "\n",
    "#Eigen decomposition of the covariance matrix after standardizing the data:\n",
    "cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\n",
    "print('Covariance matrix \\n%s' %cov_mat)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "print('Eigen vectors \\n%s' %eig_vecs)\n",
    "print('Eigen values \\n%s' %eig_vals)\n",
    "\n",
    "#Eigen decomposition of the standardized data based on the correlation matrix:\n",
    "cor_mat1 = np.corrcoef(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat1)\n",
    "print('\\nEigen vectors obtained after decomposition of the standardized data \\n%s' %eig_vecs)\n",
    "print('Eigen values are: \\n%s' %eig_vals)\n",
    "\n",
    "#Eigen decomposition of the raw data based on the correlation matrix:\n",
    "cor_mat2 = np.corrcoef(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "print('\\n Eigen vectors obtained after decomposition of the raw data \\n%s' %eig_vecs)\n",
    "print('Eigen values are:\\n%s' %eig_vals)\n",
    "\n",
    "for ev in eig_vecs.T:\n",
    "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
    "\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sorting the eigen values...\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print('\\n\\nEigen values in descending order:\\t')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])\n",
    "    \n",
    "#Matrix W is a 4 X 4 matrix, but we need a 4 X 3 matrix to do multiplication with a 150 X 4 matrix\n",
    "matrix_w = np.hstack((eig_pairs[0][1].reshape(4,1),eig_pairs[1][1].reshape(4,1),eig_pairs[2][1].reshape(4,1),eig_pairs[3][1].reshape(4,1)))\n",
    "print('\\n Original matrix is:\\n',matrix_w)\n",
    "#Deleting the last row so that it becomes a 4 X 3 matrix\n",
    "matrix_w = np.delete(matrix_w, (3),axis=0)\n",
    "print('\\nMatrix W after deleting last row:\\n', matrix_w)\n",
    "\n",
    "#The previous step resulted in 3 X 4 matrix, but we need a 4 X 3 to facilitate multiplication\n",
    "#Therefore we obtain a 4 X 3 matrix by transposing it...\n",
    "print('\\nTransposed Matrix:')\n",
    "tmatrix_wnew=(np.transpose(matrix_w))\n",
    "print(tmatrix_w)\n",
    "\n",
    "Y = X_std.dot(tmatrix_w)\n",
    "#print(\"\\n The resulting matrix is: \\n\",Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the IRIS dataset after performing PCA:\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "df = sns.load_dataset('iris')\n",
    "my_dpi=96\n",
    "plt.figure(figsize=(480/my_dpi, 480/my_dpi), dpi=my_dpi)\n",
    "df['species']=pd.Categorical(df['species'])\n",
    "my_color=df['species'].cat.codes\n",
    "df = df.drop('species', 1)\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(df)\n",
    "result=pd.DataFrame(pca.transform(df), columns=['PCA%i' % i for i in range(3)], index=df.index)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(result['PCA0'], result['PCA1'], result['PCA2'], c=my_color, cmap=\"Set2_r\", s=60)\n",
    "#ax.scatter(data['sepal_len'], data['sepal_wid'], data['petal_len'], c=my_color, cmap=\"Set2_r\", s=60)\n",
    "xAxisLine = ((min(result['PCA0']), max(result['PCA0'])), (0, 0), (0,0))\n",
    "ax.plot(xAxisLine[0], xAxisLine[1], xAxisLine[2], 'r')\n",
    "yAxisLine = ((0, 0), (min(result['PCA1']), max(result['PCA1'])), (0,0))\n",
    "ax.plot(yAxisLine[0], yAxisLine[1], yAxisLine[2], 'r')\n",
    "zAxisLine = ((0, 0), (0,0), (min(result['PCA2']), max(result['PCA2'])))\n",
    "ax.plot(zAxisLine[0], zAxisLine[1], zAxisLine[2], 'r')\n",
    "ax.set_xlabel(\"PCA1\")\n",
    "ax.set_ylabel(\"PCA2\")\n",
    "ax.set_zlabel(\"PCA3\")\n",
    "ax.set_title(\"PCA on the IRIS dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train set:  92\n",
      "Length of Test set:  58\n",
      "Enter the value Of K:3\n",
      "Accuracy: 94.82758620689656%\n"
     ]
    }
   ],
   "source": [
    "# Applying KNN on IRIS data set\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "#This function is used to load the dataset\n",
    "def loadDataset(filename, split, trainingSet=[] , testSet=[]):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        for x in range(len(dataset)-1):\n",
    "            for y in range(4):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "            if  random.random()<split:\n",
    "                trainingSet.append(dataset[x])\n",
    "            else:\n",
    "                testSet.append(dataset[x])\n",
    "\n",
    "#Function to calculate Euclidean distance\n",
    "def euclideanDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += pow((instance1[x] - instance2[x]), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "#Used to find the k-nearest neighbours\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)-1  #Number of attribute...\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist)) \n",
    "        distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    #Sort it in descending order based on 1st attribute...\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #print('classVotes=',sortedVotes[0][0])\n",
    "    return sortedVotes[0][0]    #Return the class name which has maximum value...\n",
    "\n",
    "#Gets the prediction in %\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def main():\n",
    "    # prepare data\n",
    "    trainingSet=[]\n",
    "    testSet=[]\n",
    "    split = 0.60\n",
    "    loadDataset('iris.csv', split , trainingSet, testSet)\n",
    "\n",
    "    print( 'Length of Train set: ', len(trainingSet))\n",
    "    print( 'Length of Test set: ', len(testSet))\n",
    "    \n",
    "    # generate predictions\n",
    "    predictions=[]\n",
    "    k=int(input(\"Enter the value Of K:\"))\n",
    "    i=0\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors = getNeighbors(trainingSet, testSet[x], k)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "        #print('predicted=' + str(result) + ', actual=' + str(testSet[x][-1]))\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: ' + str(accuracy) + '%')\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
